CA1: 
The goal of this assignment is to build a behavior detector (classifier), using the data in ca1-dataset.csv
This data set involves a set of clips, generated from field observations synchronized with log files. You must build a detector of the behavior OffTask (e.g. a detector that can predict if the column OffTask is Y or N). You should make sure that your detector is not over-fit, paying particular attention to making sure that your detector does not use features that could not be used when applying the model to new data or new students. This can be done both by restricting the features used during model fitting, and setting up cross-validation in an appropriate fashion.
You must build the detector using an automated algorithm. You cannot simulate the algorithm in Excel. You can use any data mining package (e.g. SAS, R, Weka, KEEL, RapidMiner, Python, Orange, Knime) you want.

CA2: The goal of this assignment is to build a better behavior detector (classifier), using the data from Creative Assignment 1, as well as new data provided for this assignment.
These two datasets represent the same data set, but at two different grain-sizes. Specifically, the new data represents individual student actions within educational software, while the previous data set is at the grain size of all the actions that occurred during 20 second field observations by trained coders. Note that the individual student actions are labeled with the same UniqueID labels as the observations are (each UniqueID corresponds to a single field observation).
In this assignment, you must conduct feature engineering to improve the features in the original data set, using the data in the new data set. You must create at least 10 new features that cannot be created using just the original data set, and add the new features to the original data set. You can create new features in Excel, or in any automated fashion you like.
Then you must build a detector of the behavior OffTask (e.g. a detector that can predict if the column OffTask is Y or N), using both the old and new feature sets (or just the new feature set). Ideally, the model with new features will have both better AUC and Kappa than the model with old features â€“ and also will have better AUC and Kappa than your hand-in for Creative Assignment 1.
As with Creative Assignment 1, you should make sure that your detector is not over-fit, paying particular attention to making sure that your detector does not use features that could not be used when applying the model to new data or new students. This can be done both by restricting the features used during model fitting, and setting up cross-validation in an appropriate fashion.
